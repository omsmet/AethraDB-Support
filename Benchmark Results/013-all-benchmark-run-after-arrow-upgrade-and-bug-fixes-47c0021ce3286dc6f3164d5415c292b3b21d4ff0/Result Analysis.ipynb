{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b658d03a",
   "metadata": {},
   "source": [
    "# AethraDB All Query Result Analysis Overview\n",
    "This file contains the result analysis for the filter query aggregation and join queries at the current stage of development in the AethraDB engine. Additionally, it contains a comparison against a single-threaded run of the same queries on the same data on DuckDB version 0.7.1 using PyArrow 11.0.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3cdcb087",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use('tableau-colorblind10')\n",
    "plt_patterns = ('-', 'x','/','\\\\','O','o','//','\\\\\\\\')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c4702e",
   "metadata": {},
   "source": [
    "## Importing the Data\n",
    "We first load the filter query benchmark data from DuckDB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5dce28d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the filter query data from DuckDB\n",
    "duckdb_filter_query_raw = pd.read_csv(\"./filter_query_duckdb.csv\")\n",
    "\n",
    "# Convert the running-time to milli-seconds\n",
    "duckdb_filter_query = duckdb_filter_query_raw.copy(deep=True)\n",
    "duckdb_filter_query[\"Running-Time\"] = duckdb_filter_query[\"Running-Time\"] * 1000\n",
    "duckdb_filter_query[\"Running-Time\"] = duckdb_filter_query[\"Running-Time\"].round(1)\n",
    "\n",
    "# Extract the restrictive column\n",
    "duckdb_filter_query[\"Restrictive-Column\"] = duckdb_filter_query.apply(lambda x: 1 if 'col1_002' in x['Dataset'] else (2 if 'col2_002' in x['Dataset'] else 3), axis=1)\n",
    "\n",
    "# Drop the dataset column\n",
    "duckdb_filter_query.drop(columns=['Dataset'], inplace=True)\n",
    "\n",
    "# Introduce the \"Engine\" column\n",
    "duckdb_filter_query[\"Engine\"] = \"DuckDB\"\n",
    "\n",
    "duckdb_filter_query.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7fbfac",
   "metadata": {},
   "source": [
    "Next, we load the aggregation query benchmark data from DuckDB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed284e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the aggregation query data from DuckDB\n",
    "duckdb_aggregation_query_raw = pd.read_csv(\"./aggregation_query_duckdb.csv\")\n",
    "\n",
    "# Convert the running-time to milli-seconds\n",
    "duckdb_aggregation_query = duckdb_aggregation_query_raw.copy(deep=True)\n",
    "duckdb_aggregation_query[\"Running-Time\"] = duckdb_aggregation_query_raw[\"Running-Time\"] * 1000\n",
    "duckdb_aggregation_query[\"Running-Time\"] = duckdb_aggregation_query[\"Running-Time\"].round(1)\n",
    "\n",
    "# Extract the number of elements in each dataset\n",
    "duckdb_aggregation_query[\"Records\"] = duckdb_aggregation_query.apply(lambda x: x['Dataset'].split('size_')[1], axis=1)\n",
    "duckdb_aggregation_query[\"Records\"] = duckdb_aggregation_query[\"Records\"].str.extract('(\\d+)').astype(int)\n",
    "\n",
    "# Extract the number of keys in each dataset\n",
    "duckdb_aggregation_query[\"Keys\"] = duckdb_aggregation_query.apply(lambda x: x['Dataset'].split('keys_')[1], axis=1)\n",
    "duckdb_aggregation_query[\"Keys\"] = duckdb_aggregation_query[\"Keys\"].str.extract('(\\d+)').astype(int)\n",
    "\n",
    "# Introduce the \"Engine\" column\n",
    "duckdb_aggregation_query[\"Engine\"] = \"DuckDB\"\n",
    "\n",
    "# Split the dataset into the skew part and without skew part\n",
    "duckdb_aggregation_query_no_skew = duckdb_aggregation_query[~duckdb_aggregation_query['Dataset'].str.contains(\"skew\")].copy(deep=True)\n",
    "\n",
    "# Drop the dataset column\n",
    "duckdb_aggregation_query_no_skew.drop(columns=['Dataset'], inplace=True)\n",
    "\n",
    "duckdb_aggregation_query_no_skew.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e040481",
   "metadata": {},
   "source": [
    "Next, we load the join query data from DuckDB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8617b219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the aggregation query data from DuckDB\n",
    "duckdb_join_query_raw = pd.read_csv(\"./join_query_duckdb.csv\")\n",
    "\n",
    "# Convert the running-time to milli-seconds\n",
    "duckdb_join_query = duckdb_join_query_raw.copy(deep=True)\n",
    "duckdb_join_query[\"Running-Time\"] = duckdb_join_query[\"Running-Time\"] * 1000\n",
    "duckdb_join_query[\"Running-Time\"] = duckdb_join_query[\"Running-Time\"].round(1)\n",
    "\n",
    "# Extract the join selectivity\n",
    "duckdb_join_query[\"B_Selectivity\"] = duckdb_join_query.apply(lambda x: x['Dataset'].split('/A_B_')[1], axis=1)\n",
    "duckdb_join_query[\"C_Selectivity\"] = duckdb_join_query.apply(lambda x: x['B_Selectivity'].split('_C_')[1], axis=1)\n",
    "duckdb_join_query[\"B_Selectivity\"] = duckdb_join_query.apply(lambda x: x['B_Selectivity'].split('_C_')[0], axis=1)\n",
    "\n",
    "# Introduce the \"Engine\" column\n",
    "duckdb_join_query[\"Engine\"] = \"DuckDB\"\n",
    "\n",
    "# Introduce the \"Dataset_ID\" column\n",
    "duckdb_join_query[\"Dataset_ID\"] = duckdb_join_query.apply(lambda x: x['Dataset'].split('/A_')[1], axis=1)\n",
    "\n",
    "# Drop the dataset column\n",
    "duckdb_join_query.drop(columns=['Dataset'], inplace=True)\n",
    "\n",
    "duckdb_join_query.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d89301",
   "metadata": {},
   "source": [
    "Finally, we load the data from the AethraDB experiments themselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfafec02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load there result from AethraDB\n",
    "aethra_result_raw = pd.read_csv(\"aethra-result.csv\")\n",
    "\n",
    "# Take only the average rows and rename the \"Score\" column to \"Running-Time\"\n",
    "aethra_results = aethra_result_raw[~aethra_result_raw['Benchmark'].str.contains('executeFilterQuery:executeFilterQuery')]\n",
    "aethra_results = aethra_results[~aethra_results['Benchmark'].str.contains('executeQuery:executeQuery')].copy(deep=True)\n",
    "aethra_results[\"Running-Time\"] = aethra_results[\"Score\"].round(1)\n",
    "\n",
    "# Introduce the \"Engine\" column\n",
    "aethra_results[\"Engine\"] = aethra_results.apply(\n",
    "    lambda x: \"NV-NS\" if 'NonVectorisedNonSimd' in x['Benchmark']\n",
    "    else (\"NV-S\" if 'NonVectorisedSimd' in x['Benchmark']\n",
    "          else (\"V-NS\" if 'VectorisedNonSimd' in x['Benchmark']\n",
    "                else \"V-S\")), axis=1)\n",
    "\n",
    "# Split the result into a filter-query, an aggregation query and a join-query dataset\n",
    "aethra_filter_query_result = aethra_results[aethra_results['Benchmark'].str.contains(\"filter_query\")].copy(deep=True)\n",
    "aethra_aggregation_query_result = aethra_results[aethra_results['Benchmark'].str.contains(\"aggregation_query\")].copy(deep=True)\n",
    "aethra_join_query_result = aethra_results[aethra_results['Benchmark'].str.contains(\"join_query\")].copy(deep=True)\n",
    "\n",
    "# For the filter-query dataset, extract the restrictive column\n",
    "aethra_filter_query_result[\"Restrictive-Column\"] = aethra_filter_query_result.apply(lambda x: 1 if 'col1_002' in x['Param: tableFilePath'] else (2 if 'col2_002' in x['Param: tableFilePath'] else 3), axis=1)\n",
    "\n",
    "# For the filter-query dataset drop all columns except the \"Running-Time\" and \"Restrictive-Column\"\n",
    "aethra_filter_query_result.drop(columns=[\"Benchmark\", \"Mode\", \"Threads\", \"Samples\", \"Score\", \"Score Error (99.9%)\", \"Unit\", \"Param: tableFilePath\", \"Param: initialMapSize\", \"Param: tpchInstance\"], inplace=True)\n",
    "\n",
    "# For the aggregation query, extract the number of elements in each dataset\n",
    "aethra_aggregation_query_result[\"Records\"] = aethra_aggregation_query_result.apply(lambda x: x['Param: tableFilePath'].split('size_')[1], axis=1)\n",
    "aethra_aggregation_query_result[\"Records\"] = aethra_aggregation_query_result[\"Records\"].str.extract('(\\d+)').astype(int)\n",
    "\n",
    "# For the aggregation query, extract the number of keys in each dataset\n",
    "aethra_aggregation_query_result[\"Keys\"] = aethra_aggregation_query_result.apply(lambda x: x['Param: tableFilePath'].split('keys_')[1], axis=1)\n",
    "aethra_aggregation_query_result[\"Keys\"] = aethra_aggregation_query_result[\"Keys\"].str.extract('(\\d+)').astype(int)\n",
    "\n",
    "# For the aggregation query, mark if the benchmark instance is a hard-coded instance\n",
    "aethra_aggregation_query_result[\"Hardcoded\"] = aethra_aggregation_query_result['Benchmark'].str.contains(\"hard_coded\")\n",
    "\n",
    "# For the aggregation query, split the dataset into the skew part and without skew part\n",
    "aethra_aggregation_query_result_no_skew = aethra_aggregation_query_result[~aethra_aggregation_query_result[\"Param: tableFilePath\"].str.contains(\"skew\")].copy(deep=True)\n",
    "\n",
    "# Drop the dataset column of the aggregation query that we do not need\n",
    "aethra_aggregation_query_result_no_skew.drop(columns=[\"Benchmark\", \"Mode\", \"Threads\", \"Samples\", \"Score\", \"Score Error (99.9%)\", \"Unit\", \"Param: tableFilePath\", \"Param: initialMapSize\", \"Param: tpchInstance\"], inplace=True)\n",
    "\n",
    "# For the join query, extract the selectivity per join column\n",
    "aethra_join_query_result[\"B_Selectivity\"] = aethra_join_query_result.apply(lambda x: x['Param: tableFilePath'].split('/A_B_')[1], axis=1)\n",
    "aethra_join_query_result[\"C_Selectivity\"] = aethra_join_query_result.apply(lambda x: x['B_Selectivity'].split('_C_')[1], axis=1)\n",
    "aethra_join_query_result[\"B_Selectivity\"] = aethra_join_query_result.apply(lambda x: x['B_Selectivity'].split('_C_')[0], axis=1)\n",
    "\n",
    "# For the join query, introduce the Dataset_ID column\n",
    "aethra_join_query_result[\"Dataset_ID\"] = aethra_join_query_result.apply(lambda x: x['Param: tableFilePath'].split('/A_')[1], axis=1)\n",
    "\n",
    "# For the join query, mark if the benchmark instance is a hard-coded instance\n",
    "aethra_join_query_result[\"Hardcoded\"] = aethra_join_query_result['Benchmark'].str.contains(\"hard_coded\")\n",
    "\n",
    "# For the join query, drop the columns that we do not need\n",
    "aethra_join_query_result.drop(columns=[\"Benchmark\", \"Mode\", \"Threads\", \"Samples\", \"Score\", \"Score Error (99.9%)\", \"Unit\", \"Param: tableFilePath\", \"Param: initialMapSize\", \"Param: tpchInstance\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08b739dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "aethra_filter_query_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05278772",
   "metadata": {},
   "outputs": [],
   "source": [
    "aethra_aggregation_query_result_no_skew.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aef0ef94",
   "metadata": {},
   "outputs": [],
   "source": [
    "aethra_join_query_result.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed5c944",
   "metadata": {},
   "source": [
    "## Analysing the Filter Query Performance\n",
    "We create a plot of the running-time per engine and per restrictive column for the filter query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d52fcb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_column = \"Restrictive-Column\"\n",
    "\n",
    "duckdb_data = duckdb_filter_query.sort_values(index_column)\n",
    "index = duckdb_data[index_column]\n",
    "\n",
    "aethra_nv_ns_data = aethra_filter_query_result[aethra_filter_query_result[\"Engine\"] == \"NV-NS\"].sort_values(index_column)\n",
    "aethra_nv_s_data = aethra_filter_query_result[aethra_filter_query_result[\"Engine\"] == \"NV-S\"].sort_values(index_column)\n",
    "aethra_v_ns_data = aethra_filter_query_result[aethra_filter_query_result[\"Engine\"] == \"V-NS\"].sort_values(index_column)\n",
    "aethra_v_s_data = aethra_filter_query_result[aethra_filter_query_result[\"Engine\"] == \"V-S\"].sort_values(index_column)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'DuckDB': duckdb_data[\"Running-Time\"].tolist(),\n",
    "    'NV-NS': aethra_nv_ns_data[\"Running-Time\"].tolist(),\n",
    "    'V-NS': aethra_v_ns_data[\"Running-Time\"].tolist(),\n",
    "    'NV-S': aethra_nv_s_data[\"Running-Time\"].tolist(),\n",
    "    'V-S': aethra_v_s_data[\"Running-Time\"].tolist(),\n",
    "}, index = index)\n",
    "\n",
    "ax = df.plot.bar(rot=0)\n",
    "ax.set_ylabel(\"Execution Time (ms)\")\n",
    "ax.set_title(\"Filter Query Running-Time per Engine\")\n",
    "\n",
    "bars = ax.patches\n",
    "hatches = [p for p in plt_patterns for i in range(len(df))]\n",
    "for bar, hatch in zip(bars, hatches):\n",
    "    bar.set_hatch(hatch)\n",
    "\n",
    "ax.legend(loc=3, bbox_to_anchor=(0., 1.06, 1., .102))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8a7362",
   "metadata": {},
   "source": [
    "## Analysing the Aggregation Query Performance (Influence of #Keys, no Skew)\n",
    "Below we analyse the performance of the Aggregation Query for each engine, where we focus on the influence of the amount of unique keys in the aggregation. We present results both for the query implementations that check the final result, and those that do not check the result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f44b49c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_column = \"Keys\"\n",
    "\n",
    "duckdb_data = duckdb_aggregation_query_no_skew.sort_values(index_column)\n",
    "index = duckdb_data[index_column]\n",
    "\n",
    "aethra_nv_ns_data = aethra_aggregation_query_result_no_skew[aethra_aggregation_query_result_no_skew[\"Engine\"] == \"NV-NS\"].sort_values(index_column)\n",
    "aethra_nv_s_data = aethra_aggregation_query_result_no_skew[aethra_aggregation_query_result_no_skew[\"Engine\"] == \"NV-S\"].sort_values(index_column)\n",
    "aethra_v_ns_data = aethra_aggregation_query_result_no_skew[aethra_aggregation_query_result_no_skew[\"Engine\"] == \"V-NS\"].sort_values(index_column)\n",
    "aethra_v_s_data = aethra_aggregation_query_result_no_skew[aethra_aggregation_query_result_no_skew[\"Engine\"] == \"V-S\"].sort_values(index_column)\n",
    "\n",
    "aethra_nv_ns_data_nhc = aethra_nv_ns_data[~aethra_nv_ns_data[\"Hardcoded\"]]\n",
    "aethra_nv_s_data_nhc = aethra_nv_s_data[~aethra_nv_s_data[\"Hardcoded\"]]\n",
    "aethra_v_ns_data_nhc = aethra_v_ns_data[~aethra_v_ns_data[\"Hardcoded\"]]\n",
    "aethra_v_s_data_nhc = aethra_v_s_data[~aethra_v_s_data[\"Hardcoded\"]]\n",
    "aethra_nv_ns_data_hc = aethra_nv_ns_data[aethra_nv_ns_data[\"Hardcoded\"]]\n",
    "aethra_nv_s_data_hc = aethra_nv_s_data[aethra_nv_s_data[\"Hardcoded\"]]\n",
    "aethra_v_ns_data_hc = aethra_v_ns_data[aethra_v_ns_data[\"Hardcoded\"]]\n",
    "aethra_v_s_data_hc = aethra_v_s_data[aethra_v_s_data[\"Hardcoded\"]]\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'DuckDB': duckdb_data[\"Running-Time\"].tolist(),\n",
    "    'NV-NS NHC': aethra_nv_ns_data_nhc[\"Running-Time\"].tolist(),\n",
    "    'V-NS NHC': aethra_v_ns_data_nhc[\"Running-Time\"].tolist(),\n",
    "    'NV-S NHC': aethra_nv_s_data_nhc[\"Running-Time\"].tolist(),\n",
    "    'V-S NHC': aethra_v_s_data_nhc[\"Running-Time\"].tolist(),\n",
    "}, index = index)\n",
    "\n",
    "ax = df.plot.bar(rot=0,figsize=(20,10))\n",
    "ax.set_ylabel(\"Execution Time (ms)\")\n",
    "ax.set_title(\"Aggregation Query Running-Time per Engine (without hard-coding) (For 31457280 Records)\")\n",
    "\n",
    "bars = ax.patches\n",
    "hatches = [p for p in plt_patterns for i in range(len(df))]\n",
    "for bar, hatch in zip(bars, hatches):\n",
    "    bar.set_hatch(hatch)\n",
    "\n",
    "ax.legend(loc=3, bbox_to_anchor=(0., 1.06, 1., .102))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f415bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'DuckDB': duckdb_data[\"Running-Time\"].tolist(),\n",
    "    'NV-NS HC': aethra_nv_ns_data_hc[\"Running-Time\"].tolist(),\n",
    "    'V-NS HC': aethra_v_ns_data_hc[\"Running-Time\"].tolist(),\n",
    "    'NV-S HC': aethra_nv_s_data_hc[\"Running-Time\"].tolist(),\n",
    "    'V-S HC': aethra_v_s_data_hc[\"Running-Time\"].tolist(),\n",
    "}, index = index)\n",
    "\n",
    "ax = df.plot.bar(rot=0,figsize=(20,10))\n",
    "ax.set_ylabel(\"Execution Time (ms)\")\n",
    "ax.set_title(\"Aggregation Query Running-Time per Engine (with hard-coding) (For 31457280 Records)\")\n",
    "\n",
    "bars = ax.patches\n",
    "hatches = [p for p in plt_patterns for i in range(len(df))]\n",
    "for bar, hatch in zip(bars, hatches):\n",
    "    bar.set_hatch(hatch)\n",
    "\n",
    "ax.legend(loc=3, bbox_to_anchor=(0., 1.06, 1., .102))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "11c1d1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'DuckDB': duckdb_data[\"Running-Time\"].tolist(),\n",
    "    'NV-NS NHC': aethra_nv_ns_data_nhc[\"Running-Time\"].tolist(),\n",
    "    'NV-NS HC': aethra_nv_ns_data_hc[\"Running-Time\"].tolist(),\n",
    "    'V-NS NHC': aethra_v_ns_data_nhc[\"Running-Time\"].tolist(),\n",
    "    'V-NS HC': aethra_v_ns_data_hc[\"Running-Time\"].tolist(),\n",
    "    'NV-S NHC': aethra_nv_s_data_nhc[\"Running-Time\"].tolist(),\n",
    "    'NV-S HC': aethra_nv_s_data_hc[\"Running-Time\"].tolist(),\n",
    "    'V-S NHC': aethra_v_s_data_nhc[\"Running-Time\"].tolist(),\n",
    "    'V-S HC': aethra_v_s_data_hc[\"Running-Time\"].tolist(),\n",
    "}, index = index)\n",
    "\n",
    "ax = df.plot.bar(rot=0,figsize=(20,10))\n",
    "ax.set_ylabel(\"Execution Time (ms)\")\n",
    "ax.set_title(\"Aggregation Query Running-Time per Engine (For 31457280 Records)\")\n",
    "\n",
    "bars = ax.patches\n",
    "hatches = [p for p in plt_patterns for i in range(len(df))]\n",
    "for bar, hatch in zip(bars, hatches):\n",
    "    bar.set_hatch(hatch)\n",
    "\n",
    "ax.legend(loc=3, bbox_to_anchor=(0., 1.06, 1., .102))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9c1bac",
   "metadata": {},
   "source": [
    "## Analysing the Join Query Performance\n",
    "Below we analyse the performance of the Join Query for each engine. The different datasets indicate the different join selectivity levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90ef68fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_column = \"Dataset_ID\"\n",
    "\n",
    "duckdb_data = duckdb_join_query.sort_values(index_column)\n",
    "index = duckdb_data[index_column]\n",
    "\n",
    "aethra_nv_ns_data = aethra_join_query_result[aethra_join_query_result[\"Engine\"] == \"NV-NS\"].sort_values(index_column)\n",
    "aethra_nv_s_data = aethra_join_query_result[aethra_join_query_result[\"Engine\"] == \"NV-S\"].sort_values(index_column)\n",
    "aethra_v_ns_data = aethra_join_query_result[aethra_join_query_result[\"Engine\"] == \"V-NS\"].sort_values(index_column)\n",
    "aethra_v_s_data = aethra_join_query_result[aethra_join_query_result[\"Engine\"] == \"V-S\"].sort_values(index_column)\n",
    "\n",
    "aethra_nv_ns_data_NHC = aethra_nv_ns_data[~aethra_nv_ns_data[\"Hardcoded\"]]\n",
    "aethra_nv_s_data_NHC = aethra_nv_s_data[~aethra_nv_s_data[\"Hardcoded\"]]\n",
    "aethra_v_ns_data_NHC = aethra_v_ns_data[~aethra_v_ns_data[\"Hardcoded\"]]\n",
    "aethra_v_s_data_NHC = aethra_v_s_data[~aethra_v_s_data[\"Hardcoded\"]]\n",
    "aethra_nv_ns_data_HC = aethra_nv_ns_data[aethra_nv_ns_data[\"Hardcoded\"]]\n",
    "aethra_nv_s_data_HC = aethra_nv_s_data[aethra_nv_s_data[\"Hardcoded\"]]\n",
    "aethra_v_ns_data_HC = aethra_v_ns_data[aethra_v_ns_data[\"Hardcoded\"]]\n",
    "aethra_v_s_data_HC = aethra_v_s_data[aethra_v_s_data[\"Hardcoded\"]]\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'DuckDB': duckdb_data[\"Running-Time\"].tolist(),\n",
    "    'NV-NS NHC': aethra_nv_ns_data_NHC[\"Running-Time\"].tolist(),\n",
    "    'V-NS NHC': aethra_v_ns_data_NHC[\"Running-Time\"].tolist(),\n",
    "    'NV-S NHC': aethra_nv_s_data_NHC[\"Running-Time\"].tolist(),\n",
    "    'V-S NHC': aethra_v_s_data_NHC[\"Running-Time\"].tolist(),\n",
    "}, index = index)\n",
    "\n",
    "ax = df.plot.bar(rot=0,figsize=(20,10))\n",
    "ax.set_ylabel(\"Execution Time (ms)\")\n",
    "ax.set_title(\"Join Query Running-Time per Engine (without hard-coding)\")\n",
    "\n",
    "bars = ax.patches\n",
    "hatches = [p for p in plt_patterns for i in range(len(df))]\n",
    "for bar, hatch in zip(bars, hatches):\n",
    "    bar.set_hatch(hatch)\n",
    "\n",
    "ax.legend(loc=3, bbox_to_anchor=(0., 1.06, 1., .102))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1be38398",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'DuckDB': duckdb_data[\"Running-Time\"].tolist(),\n",
    "    'NV-NS HC': aethra_nv_ns_data_HC[\"Running-Time\"].tolist(),\n",
    "    'V-NS HC': aethra_v_ns_data_HC[\"Running-Time\"].tolist(),\n",
    "    'NV-S HC': aethra_nv_s_data_HC[\"Running-Time\"].tolist(),\n",
    "    'V-S HC': aethra_v_s_data_HC[\"Running-Time\"].tolist(),\n",
    "}, index = index)\n",
    "\n",
    "ax = df.plot.bar(rot=0,figsize=(20,10))\n",
    "ax.set_ylabel(\"Execution Time (ms)\")\n",
    "ax.set_title(\"Join Query Running-Time per Engine (with hard-coding)\")\n",
    "\n",
    "bars = ax.patches\n",
    "hatches = [p for p in plt_patterns for i in range(len(df))]\n",
    "for bar, hatch in zip(bars, hatches):\n",
    "    bar.set_hatch(hatch)\n",
    "\n",
    "ax.legend(loc=3, bbox_to_anchor=(0., 1.06, 1., .102))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a1405509",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'DuckDB': duckdb_data[\"Running-Time\"].tolist(),\n",
    "    'NV-NS NHC': aethra_nv_ns_data_NHC[\"Running-Time\"].tolist(),\n",
    "    'NV-NS HC': aethra_nv_ns_data_HC[\"Running-Time\"].tolist(),\n",
    "    'V-NS NHC': aethra_v_ns_data_NHC[\"Running-Time\"].tolist(),\n",
    "    'V-NS HC': aethra_v_ns_data_HC[\"Running-Time\"].tolist(),\n",
    "    'NV-S NHC': aethra_nv_s_data_NHC[\"Running-Time\"].tolist(),\n",
    "    'NV-S HC': aethra_nv_s_data_HC[\"Running-Time\"].tolist(),\n",
    "    'V-S NHC': aethra_v_s_data_NHC[\"Running-Time\"].tolist(),\n",
    "    'V-S HC': aethra_v_s_data_HC[\"Running-Time\"].tolist()\n",
    "}, index = index)\n",
    "\n",
    "ax = df.plot.bar(rot=0,figsize=(20,10))\n",
    "ax.set_ylabel(\"Execution Time (ms)\")\n",
    "ax.set_title(\"Join Query Running-Time per Engine\")\n",
    "\n",
    "bars = ax.patches\n",
    "hatches = [p for p in plt_patterns for i in range(len(df))]\n",
    "for bar, hatch in zip(bars, hatches):\n",
    "    bar.set_hatch(hatch)\n",
    "\n",
    "ax.legend(loc=3, bbox_to_anchor=(0., 1.06, 1., .102))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681d55d8",
   "metadata": {},
   "source": [
    "## TPC-H Query Analysis\n",
    "In the section below we study the performance of the three TPC-H queries that are currently supported by the AethraDB engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "69369915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we load the data\n",
    "aethra_results_tpch = aethra_results[aethra_results[\"Benchmark\"].str.contains(\"benchmarks.tpch\")].copy(deep=True)\n",
    "\n",
    "# Update the engine column to account for reduced mask benchmarks\n",
    "aethra_results_tpch[\"Engine\"] = aethra_results_tpch.apply(\n",
    "    lambda x: \"NV-NS\" if 'NonVectorisedNonSimd' in x['Benchmark']\n",
    "    else (\"NV-S\" if 'NonVectorisedSimd' in x['Benchmark']\n",
    "          else (\"V-NS\" if 'VectorisedNonSimd' in x['Benchmark'] and \"Red\" not in x['Benchmark']\n",
    "                else (\"V-NS-Red\" if 'VectorisedNonSimd' in x['Benchmark']\n",
    "                      else (\"V-S\" if 'VectorisedSimd' in x['Benchmark'] and \"Red\" not in x['Benchmark']\n",
    "                           else \"V-S-Red\")))), axis=1)\n",
    "\n",
    "# Next create a column indicating the TPC-H Query\n",
    "aethra_results_tpch[\"Query\"] = aethra_results_tpch[\"Benchmark\"].apply(lambda x: x.split(\".\")[2].replace(\"_hard_coded\", \"\"))\n",
    "\n",
    "# Introduce a column indicating whether the execution of the query is hard-coded\n",
    "aethra_results_tpch[\"Hardcoded\"] = aethra_results_tpch[\"Benchmark\"].str.contains(\"hard_coded\")\n",
    "\n",
    "# Remove columns that are no longer necessary\n",
    "aethra_results_tpch.drop(columns=[\"Benchmark\", \"Mode\", \"Threads\", \"Samples\", \"Score\", \"Score Error (99.9%)\", \"Unit\", \"Param: tableFilePath\", \"Param: initialMapSize\", \"Param: tpchInstance\"], inplace=True)\n",
    "\n",
    "# Print the resulting data for verification\n",
    "aethra_results_tpch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ed8792e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the DuckDB reference data\n",
    "duckdb_tpch = pd.read_csv(\"./tpch_queries_duckdb.csv\")\n",
    "\n",
    "duckdb_tpch[\"Running-Time\"] = duckdb_tpch[\"Running-Time\"].round(1)\n",
    "\n",
    "# Introduce the \"Engine\" column\n",
    "duckdb_tpch[\"Engine\"] = \"DuckDB\"\n",
    "\n",
    "duckdb_tpch.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8b2a9846",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_column = \"Query\"\n",
    "\n",
    "duckdb_data = duckdb_tpch.sort_values(index_column)\n",
    "index = duckdb_data[index_column]\n",
    "\n",
    "aethra_nv_ns_data = aethra_results_tpch[aethra_results_tpch[\"Engine\"] == \"NV-NS\"].sort_values(index_column)\n",
    "aethra_nv_s_data = aethra_results_tpch[aethra_results_tpch[\"Engine\"] == \"NV-S\"].sort_values(index_column)\n",
    "aethra_v_ns_data = aethra_results_tpch[aethra_results_tpch[\"Engine\"] == \"V-NS\"].sort_values(index_column)\n",
    "aethra_v_ns_red_data = aethra_results_tpch[aethra_results_tpch[\"Engine\"] == \"V-NS-Red\"].sort_values(index_column)\n",
    "aethra_v_s_data = aethra_results_tpch[aethra_results_tpch[\"Engine\"] == \"V-S\"].sort_values(index_column)\n",
    "aethra_v_s_red_data = aethra_results_tpch[aethra_results_tpch[\"Engine\"] == \"V-S-Red\"].sort_values(index_column)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'DuckDB': duckdb_data[\"Running-Time\"].tolist(),\n",
    "    'NV-NS': aethra_nv_ns_data[\"Running-Time\"].tolist(),\n",
    "    'V-NS': aethra_v_ns_data[\"Running-Time\"].tolist(),\n",
    "    'V-NS-Red': aethra_v_ns_red_data[\"Running-Time\"].tolist(),\n",
    "    'NV-S': aethra_nv_s_data[\"Running-Time\"].tolist(),\n",
    "    'V-S': aethra_v_s_data[\"Running-Time\"].tolist(),\n",
    "    'V-S-Red': aethra_v_s_red_data[\"Running-Time\"].tolist()\n",
    "}, index = index)\n",
    "\n",
    "ax = df.plot.bar(rot=0,figsize=(20,10))\n",
    "ax.set_ylabel(\"Execution Time (ms)\")\n",
    "ax.set_title(\"TPC-H Running-Time for Various Queries per Engine (all hard-coded)\")\n",
    "\n",
    "bars = ax.patches\n",
    "hatches = [p for p in plt_patterns for i in range(len(df))]\n",
    "for bar, hatch in zip(bars, hatches):\n",
    "    bar.set_hatch(hatch)\n",
    "\n",
    "ax.legend(loc=3, bbox_to_anchor=(0., 1.06, 1., .102))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
